/**
 * Train the Header Classifier Model
 *
 * This script uses the training data generated by trainingDataGenerator.js
 * to train the HeaderClassifier model. Refactored to use shared utilities.
 */

const fs = require("fs");
const path = require("path");
const { SimpleHeaderClassifier } = require("./simpleHeaderClassifier");
const { generateTrainingData } = require("./trainingDataGenerator");
const {
  DataSplitter,
  DatasetBalancer,
  MLFileUtils,
  PATHS,
} = require("../utils/headerFilterUtils");

const TRAINING_DIR = path.join(__dirname, "../ml");
const MODEL_DIR = path.join(__dirname, "../ml");
const MODEL_PATH = path.join(MODEL_DIR, "header_classifier.json");

/**
 * Balance the dataset to address class imbalance
 * @param {Array} data - Original dataset
 * @returns {Array} Balanced dataset
 */
function balanceDataset(data) {
  const headers = data.filter((item) => item.isHeader);
  const nonHeaders = data.filter((item) => !item.isHeader);

  console.log(
    `Original distribution - Headers: ${headers.length}, Non-headers: ${nonHeaders.length}`
  );

  // Oversample headers or undersample non-headers
  const targetSize = Math.min(headers.length * 3, nonHeaders.length);

  // Shuffle non-headers and take subset
  const shuffleArray = (array) => {
    const shuffled = [...array];
    for (let i = shuffled.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
    }
    return shuffled;
  };

  const balancedNonHeaders = shuffleArray(nonHeaders).slice(0, targetSize);

  console.log(
    `Balanced distribution - Headers: ${headers.length}, Non-headers: ${balancedNonHeaders.length}`
  );

  return [...headers, ...balancedNonHeaders];
}

/**
 * Stratified sampling for train/test split
 * @param {Array} data - Dataset
 * @param {number} testRatio - Test ratio
 * @returns {Object} Stratified train/test split
 */
function stratifiedSplit(data, testRatio = 0.2) {
  const headers = data.filter((item) => item.isHeader);
  const nonHeaders = data.filter((item) => !item.isHeader);

  const headerTestSize = Math.floor(headers.length * testRatio);
  const nonHeaderTestSize = Math.floor(nonHeaders.length * testRatio);

  // Shuffle both classes
  const shuffledHeaders = [...headers].sort(() => Math.random() - 0.5);
  const shuffledNonHeaders = [...nonHeaders].sort(() => Math.random() - 0.5);

  const testData = [
    ...shuffledHeaders.slice(0, headerTestSize),
    ...shuffledNonHeaders.slice(0, nonHeaderTestSize),
  ];

  const trainData = [
    ...shuffledHeaders.slice(headerTestSize),
    ...shuffledNonHeaders.slice(nonHeaderTestSize),
  ];

  // Shuffle final datasets
  testData.sort(() => Math.random() - 0.5);
  trainData.sort(() => Math.random() - 0.5);

  return { trainData, testData };
}

async function trainModel() {
  try {
    // Create model directory if it doesn't exist
    MLFileUtils.ensureDirectoryExists(MODEL_DIR);

    // Generate training data if needed
    const trainingDataPath = path.join(
      TRAINING_DIR,
      "header_training_data.json"
    );
    if (!fs.existsSync(trainingDataPath)) {
      console.log("ðŸ”„ Generating training data...");
      await generateTrainingData();
    }

    // Load training data
    const allTrainingData = MLFileUtils.loadJsonFile(trainingDataPath, []);
    if (allTrainingData.length === 0) {
      throw new Error("No training data available");
    }

    // Balance the dataset to address class imbalance
    const balancedData = DatasetBalancer.balanceDataset(allTrainingData);

    // Use stratified sampling for train/test split
    const { trainData, testData } = DataSplitter.stratifiedSplit(
      balancedData,
      0.2
    );

    console.log(
      `Training with ${trainData.length} samples, testing with ${testData.length} samples`
    );

    // Initialize and train the classifier
    const classifier = new SimpleHeaderClassifier();
    classifier.train(trainData);

    // Evaluate the model on test set
    console.log("\nðŸ“Š Model Performance Metrics:");
    console.log("=".repeat(40));

    const metrics = classifier.evaluateMetrics(testData); // Quick evaluation
    console.log(`Accuracy:  ${metrics.accuracy}%`);
    console.log(`Precision: ${metrics.precision}%`);
    console.log(`Recall:    ${metrics.recall}%`);
    console.log(`F1 Score:  ${metrics.f1Score}%`);

    console.log("\nðŸ“‹ Confusion Matrix:");
    console.log(`True Positives:  ${metrics.confusionMatrix.truePositives}`);
    console.log(`False Positives: ${metrics.confusionMatrix.falsePositives}`);
    console.log(`True Negatives:  ${metrics.confusionMatrix.trueNegatives}`);
    console.log(`False Negatives: ${metrics.confusionMatrix.falseNegatives}`);

    // Save the trained model
    console.log("\nðŸ’¾ Saving model...");
    classifier.save(MODEL_PATH);

    console.log(`\nâœ… Model trained and saved to ${MODEL_PATH}`);
    console.log(
      "\nðŸ’¡ Run 'node evaluateModelMetrics.js' for detailed performance analysis"
    );
  } catch (error) {
    console.error("âŒ Training failed:", error);
    process.exit(1);
  }
}

// Main execution
(async () => {
  console.log("ðŸ¤– Starting Header Classification Training");
  console.log("=".repeat(50));
  await trainModel();
})();
